{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565fa044-df29-47f9-9e1e-01e1caf43185",
   "metadata": {},
   "source": [
    "### HCP Performance Evaluation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70356e78-26a1-4e28-874a-874da18351bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# Binary perfomance metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Import this module with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import llmt\n",
    "from llmt.performance import binary_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804ea35-3aa5-42ce-a452-6aaa8ebf90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.environ.get('HOME'), 'home_data', 'hcp')\n",
    "results_file_name = 'predict_mental_health_250414.parquet'\n",
    "results_file = os.path.join(data_dir, results_file_name)\n",
    "df = pd.read_parquet(results_file)\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c45f2-a6ef-4dfa-9895-d88d3a36a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the predicted variables and ground truth rows\n",
    "var_col = 'mental_health'\n",
    "pred_col = 'predict_mh'\n",
    "pred_score_col = 'predict_mh_score'\n",
    "\n",
    "var_cols = ['id', 'name', 'description', var_col, pred_col, pred_score_col]\n",
    "pred_vals = [0, 1]\n",
    "df_var = df.loc[df[var_col].isin(pred_vals)][var_cols].\\\n",
    "                reset_index(drop=True)\n",
    "print(df_var.shape)\n",
    "display(df_var.head(2))\n",
    "\n",
    "y_true = list(df_var[var_col].values)\n",
    "y_pred = list(df_var[pred_col].values)\n",
    "y_pred = [1 if pred else 0 for pred in y_pred]\n",
    "y_true = [int(y) for y in y_true]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c65f0e-b246-4a0f-ada1-94d14198d3d9",
   "metadata": {},
   "source": [
    "### Performance metrics manual calculation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890f384-f48b-455f-bd63-9f901161d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original performance\n",
    "performance_dict = binary_performance(y_true=y_true, y_pred=y_pred)\n",
    "display(performance_dict)\n",
    "# Performance if we set all prediction to 1 \n",
    "print()\n",
    "performance_dict_1 = binary_performance(y_true=y_true, y_pred=np.ones(len(y_pred)))\n",
    "display(performance_dict_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9118ba1f-5322-49bc-b34a-9ae575d6b951",
   "metadata": {},
   "source": [
    "### Evaluate false positives ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726c573-ec03-43dd-b32a-f1db6bc9de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_idx = [idx for idx in range(len(y_true)) if (y_true[idx] == 0) & (y_pred[idx] == 1)]\n",
    "fp_id = df_var.loc[df_var.index.isin(fp_idx), 'id'].values\n",
    "\n",
    "print(fp_idx)\n",
    "\n",
    "for company_id in fp_id[:2]:\n",
    "    df_company = df_var.loc[df_var['id'] == company_id]\n",
    "    display(df_company)\n",
    "    print(df_company['name'].values[0])\n",
    "    print(df_company['description'].values[0])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
