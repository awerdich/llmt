{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c034dd-6222-4e73-bd30-6693f4fa62b9",
   "metadata": {},
   "source": [
    "### Script to run all prompts on the data set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855ae84-3c04-4677-a51d-63a91a96f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Import this module with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import llmt\n",
    "from llmt.llmtools import Prompt\n",
    "from llmt.llmtools import process_prompt\n",
    "from llmt.openai import OpenAIModel, OpenAI\n",
    "from llmt.openai import MentalHealth, OutpatientServices, InpatientServices, create_messages\n",
    "from llmt.performance import Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b1d27-85e6-465b-9d58-c7d5e79d93e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories and files\n",
    "data_dir = os.path.join(os.environ.get('HOME'), 'home_data', 'hcp')\n",
    "experiment_name = 'hcp_experiment_01'\n",
    "output_dir = os.path.join(data_dir, experiment_name)\n",
    "Path(output_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "test_file_name = 'hcp-alldata-250413.parquet'\n",
    "test_file = os.path.join(data_dir, test_file_name)\n",
    "df_all = pd.read_parquet(test_file)\n",
    "# Filter the labeled data\n",
    "df_train = df_all.loc[df_all['dset'] == 'train'].\\\n",
    "                reset_index(drop=True).\\\n",
    "                astype({'mental_health': int,\n",
    "                        'inpatient': int,\n",
    "                        'outpatient': int})\n",
    "display(df_train.head())\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac16dc8-640f-4a8e-9240-30328fd4a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some additional samples \n",
    "test_samples = 0\n",
    "random_state = 111\n",
    "df_test = df_all.loc[df_all['mental_health'].isnull()].\\\n",
    "                sample(n=test_samples, replace=False, random_state=random_state).\\\n",
    "                reset_index(drop=True)\n",
    "# Combine the training and test samples\n",
    "df = pd.concat([df_train, df_test], axis=0, ignore_index=True).\\\n",
    "                sample(frac=1, random_state=random_state).\\\n",
    "                reset_index(drop=True)\n",
    "for dset in ['train', 'test']:\n",
    "    print(f'{dset}: {len(df.loc[df['dset']==dset, 'id'].unique())}')\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34c8e8-f67f-4a14-ae00-58788f585831",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0 \n",
    "runs = 1\n",
    "results_file_base = f'250421_results'\n",
    "\n",
    "# Run the prompt on all data\n",
    "company_id_list = sorted(list(df['id'].unique()))\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# Instantiate the model class\n",
    "model = OpenAIModel()\n",
    "\n",
    "for run in range(runs):\n",
    "    execution_time = time.perf_counter() - start_time\n",
    "    execution_time_min = np.round(execution_time/60, decimals=1)\n",
    "    print(f'Execution time: {execution_time_min} minutes.')\n",
    "    results_run_file_name = f'{results_file_base}_{str(run).zfill(2)}.parquet'\n",
    "    results_run_file = os.path.join(output_dir, results_run_file_name)\n",
    "    print(f'STARTING RUN {run + 1} / {runs}: {results_run_file_name}')\n",
    "    results_run_df_list = []\n",
    "    for c, company_id in enumerate(company_id_list):\n",
    "        if (c + 1) % 20 == 0:\n",
    "            print(f'Sending description {c + 1} / {len(company_id_list)} to the model')\n",
    "    \n",
    "        df_id = df.loc[df['id'] == company_id]\n",
    "        name = df_id['name'].values[0]\n",
    "        description = df_id['description'].values[0]\n",
    "        \n",
    "        # Mental health predictions\n",
    "        response_mh = model.predict_mh(name=name, description=description, version=2, temperature=temperature)\n",
    "        df_id = df_id.assign(**response_mh)\n",
    "        \n",
    "        # Inpatient predictions\n",
    "        response_ip = model.predict_ip(name=name, description=description, version=1, temperature=temperature)\n",
    "        df_id = df_id.assign(**response_ip)\n",
    "        \n",
    "        # Outpatient predictions\n",
    "        response_op = model.predict_op(name=name, description=description, version=1, temperature=temperature)\n",
    "        df_id = df_id.assign(**response_op)\n",
    "\n",
    "        results_run_df_list.append(df_id)\n",
    "\n",
    "    # Add the new data frame to the list\n",
    "    results_run_df = pd.concat(results_run_df_list, axis=0, ignore_index=True)\n",
    "    results_run_df = results_run_df.assign(temperature=temperature)\n",
    "    # Save it\n",
    "    results_run_df.to_parquet(results_run_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89aca69-9d9d-44ee-8d0f-c4e9fe47a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and check the results\n",
    "# results_file_name = 'inpatient_01_results.parquet'\n",
    "results_file_name = f'hcp_experiment_01_01_t1.parquet'\n",
    "results_file = os.path.join(output_dir, results_file_name)\n",
    "df = pd.read_parquet(results_file)\n",
    "\n",
    "results_train = df.loc[df['dset'] == 'train']\n",
    "\n",
    "# Mapping true variable and predictions\n",
    "variable_dict = {'mental_health': 'pred_mh',\n",
    "                 'inpatient': 'pred_ip',\n",
    "                 'outpatient': 'pred_op'}\n",
    "\n",
    "for true_col in variable_dict.keys():\n",
    "    print(f'PERFORMANCE: {true_col.upper()}')\n",
    "    display(Performance(data=df.copy()).\\\n",
    "            binary_performance(true_col=true_col, pred_col=variable_dict.get(true_col)))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
