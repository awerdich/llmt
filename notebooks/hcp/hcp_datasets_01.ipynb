{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b68ce7a-d58b-49f7-b517-17fdae85ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent\n",
    "import logging\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Appearance of the Notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "np.set_printoptions(linewidth=110)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Import this module with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import llmt\n",
    "# print(f'Package version: {llmt.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e68427-53ac-4018-9eb6-1c40cc920f4d",
   "metadata": {},
   "source": [
    "### Load the data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d53e9c-1d6a-49a9-b410-3eb90a4d5084",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = datetime.date.today().strftime('%y%m%d')\n",
    "data_dir = os.path.join(os.environ.get('HOME'), 'home_data', 'hcp')\n",
    "xls_file_1 = 'inpatient-companies-classification-03.18.2024.xlsx'\n",
    "xls_file_2 = 'inpatient-companies-classification-Additional negs-04.01.2025.xlsx'\n",
    "\n",
    "# Create a new data frame with the cleaned-up data frame\n",
    "output_file_name = f'hcp-alldata-250413.parquet'\n",
    "output_file = os.path.join(data_dir, output_file_name)\n",
    "\n",
    "df1 = pd.read_excel(os.path.join(data_dir, xls_file_1))\n",
    "df2 = pd.read_excel(os.path.join(data_dir, xls_file_2))\n",
    "\n",
    "print(df1.shape)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c8203-59e1-4507-ab05-6eeb62ff7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f2da3-adfa-43d0-b6d5-06ffc21912fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up and rename the columns\n",
    "def clean_df(data, labeled_rows='train', un_labeled_rows='test'):\n",
    "    df = copy.deepcopy(data).\\\n",
    "                    rename(columns={'Companies': 'name',\n",
    "                                    'CompanyID': 'id',\n",
    "                                    'Description': 'description',\n",
    "                                    'inpatient_healthcare ': 'inpatient',\n",
    "                                    'outpatient_healthcare': 'outpatient'})\n",
    "    cols = ['id', 'name', 'description', 'mental_health', 'inpatient', 'outpatient']\n",
    "    df = df[cols]\n",
    "    \n",
    "    # Select one row per id\n",
    "    n_id_before = len(df['id'].unique())\n",
    "    df = df.drop_duplicates(subset='id', keep='first', ignore_index=True)\n",
    "    n_id_after = len(df['id'].unique())\n",
    "    assert n_id_before == n_id_after\n",
    "    df = df.assign(dset=None)\n",
    "    df.loc[~df['mental_health'].isnull(), 'dset'] = labeled_rows\n",
    "    df.loc[df['mental_health'].isnull(), 'dset'] = un_labeled_rows\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c22df4-6343-462d-9f8f-a33c8c2d6cd7",
   "metadata": {},
   "source": [
    "### Check the labels for the duplicate IDs ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c5b7f-291b-447e-be13-768cbceeec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_cleaned = clean_df(data=df1)\n",
    "df2_cleaned = clean_df(data=df2)\n",
    "df1_labeled = df1_cleaned.loc[df1_cleaned['dset'] == 'train']\n",
    "df2_labeled = df2_cleaned.loc[df2_cleaned['dset'] == 'train']\n",
    "\n",
    "# The company IDs are unique\n",
    "print(df1_labeled.shape)\n",
    "print(len(df1_labeled['id'].unique()))\n",
    "print(df2_labeled.shape)\n",
    "print(len(df2_labeled['id'].unique()))\n",
    "duplicate_id_list = []\n",
    "df2_id_list = df2_labeled['id'].unique()\n",
    "for id2 in df2_id_list:\n",
    "    df1_id = df1_labeled.loc[df1_labeled['id'] == id2]\n",
    "    if len(df1_id) > 0:\n",
    "        duplicate_id_list.append(id2)\n",
    "        df2_id = df2_labeled.loc[df2_labeled['id'] == id2]\n",
    "#        display(df1_id)\n",
    "#        display(df2_id)\n",
    "\n",
    "# Are the duplicate rows are the same\n",
    "d1 = df1_labeled.loc[df1_labeled['id'].isin(duplicate_id_list)].\\\n",
    "                sort_values(by='id', ascending=True).\\\n",
    "                reset_index(drop=True).\\\n",
    "                astype({'inpatient': int, 'outpatient': int, 'mental_health': int})\n",
    "d2 = df2_labeled.loc[df2_labeled['id'].isin(duplicate_id_list)].\\\n",
    "                sort_values(by='id', ascending=True).\\\n",
    "                reset_index(drop=True)\n",
    "\n",
    "print(f'The labels for the duplicate IDs are the same: {d1.equals(d2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85252619-8f71-4c8c-b539-d31940fbaac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data sets\n",
    "df = pd.concat([df1_cleaned, df2_cleaned], axis=0, ignore_index=True)\n",
    "\n",
    "# Get the training samples with labels\n",
    "df_train = df.loc[df['dset'] == 'train'].\\\n",
    "                drop_duplicates().\\\n",
    "                reset_index(drop=True)\n",
    "df_train_id_list = list(df_train['id'].unique())\n",
    "\n",
    "# Get the test samples without labels\n",
    "df_test = df.loc[df['dset'] == 'test'].\\\n",
    "                drop_duplicates().\\\n",
    "                reset_index(drop=True)\n",
    "df_test_id_list = list(df_test['id'].unique())\n",
    "\n",
    "# Remove the ids from this list where we already have labels\n",
    "df_test_id_list_diff = set(df_test_id_list).difference(df_train_id_list)\n",
    "\n",
    "print(f'Number of IDs in the test set before removing duplicates: {len(df_test_id_list)}')\n",
    "print(f'Number of IDs in the test set after removing duplicates:  {len(df_test_id_list_diff)}')\n",
    "print(f'Removing {len(df_test_id_list) - len(df_test_id_list_diff)} duplicate samples from test set.')\n",
    "df_test = df_test[df_test['id'].isin(df_test_id_list_diff)]\n",
    "\n",
    "# Combine the train and test sets\n",
    "df_combined = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "# Make sure that the ids are unique\n",
    "print(len(df_combined['id'].unique()))\n",
    "print(df_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f2950e-d2b2-420d-bd29-c5f2867c919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final data frame\n",
    "df_combined.to_parquet(output_file)\n",
    "display(df_combined.head())\n",
    "print()\n",
    "display(df_combined.sample(5))\n",
    "print(output_file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
