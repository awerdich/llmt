{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c034dd-6222-4e73-bd30-6693f4fa62b9",
   "metadata": {},
   "source": [
    "### Script to run all prompts on the data set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855ae84-3c04-4677-a51d-63a91a96f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Import this module with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import llmt\n",
    "from llmt.llmtools import Prompt\n",
    "from llmt.llmtools import MentalHealth, OutpatientServices\n",
    "from llmt.llmtools import process_prompt\n",
    "from llmt.openai import OpenAI, create_messages\n",
    "from llmt.performance import Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b1d27-85e6-465b-9d58-c7d5e79d93e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "# Directories and files\n",
    "data_dir = os.path.join(os.environ.get('HOME'), 'home_data', 'hcp')\n",
    "test_file_name = 'hcp-alldata-250413.parquet'\n",
    "test_file = os.path.join(data_dir, test_file_name)\n",
    "df_all = pd.read_parquet(test_file)\n",
    "# Filter the labeled data\n",
    "df_train = df_all.loc[df_all['dset'] == 'train'].\\\n",
    "                reset_index(drop=True).\\\n",
    "                astype({'mental_health': int,\n",
    "                        'inpatient': int,\n",
    "                        'outpatient': int})\n",
    "display(df_train.head())\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac16dc8-640f-4a8e-9240-30328fd4a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some additional samples \n",
    "test_samples = 5\n",
    "random_state = 234\n",
    "df_test = df_all.loc[df_all['mental_health'].isnull()].\\\n",
    "                sample(n=test_samples, replace=False, random_state=random_state).\\\n",
    "                reset_index(drop=True)\n",
    "# Combine the training and test samples\n",
    "df = pd.concat([df_train, df_test], axis=0, ignore_index=True).\\\n",
    "                sample(frac=1, random_state=random_state).\\\n",
    "                reset_index(drop=True)\n",
    "for dset in ['train', 'test']:\n",
    "    print(f'{dset}: {len(df.loc[df['dset']==dset, 'id'].unique())}')\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6d0d9-350e-4338-9016-cac4d42d76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mh(name, description, variable, version, client=None): \n",
    "    model = 'gpt-4o'\n",
    "    temperature = 0\n",
    "    response_format = MentalHealth\n",
    "    prompt_name = f'{variable}_system_{str(prompt_version).zfill(2)}'\n",
    "    system_prompt = Prompt().load(prompt_name=prompt_name)\n",
    "    user_prompt = process_prompt(f\"\"\"\n",
    "                    The organization {name} is described as: {description} \n",
    "                    Does this organization provide {variable} healthcare services?\n",
    "                    \"\"\")\n",
    "    messages = create_messages(system_prompt=system_prompt, user_prompt=user_prompt)\n",
    "    output = OpenAI().send_messages(messages=messages,\n",
    "                                    model=model,\n",
    "                                    temperature=temperature,\n",
    "                                    response_format=response_format,\n",
    "                                    client=client)\n",
    "    # Replace the boolean with binary outcome prediction\n",
    "    key = 'pred_mh'\n",
    "    output.update({key: 1 if output.get(key) == True else 0})\n",
    "    # Select the fields that we want \n",
    "    output = {key: output.get(key)}\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5791dfd2-f715-4763-9ef4-4f78b76e4990",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_id_list = sorted(list(df['id'].unique()))\n",
    "company_id = company_id_list[10]\n",
    "df_id = df.loc[df['id'] == company_id]\n",
    "display(df_id)\n",
    "variable = 'mental_health'\n",
    "version = 2\n",
    "name = df_id['name'].values[0]\n",
    "description = df_id['description'].values[0]\n",
    "output = predict_mh(name=name, description=description, variable=variable, version=version)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030b7c19-3682-4b3e-8199-4c686ea296c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34c8e8-f67f-4a14-ae00-58788f585831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the prompt on all data\n",
    "company_id_list = sorted(list(df['id'].unique()))\n",
    "results_df_list = []\n",
    "\n",
    "for c, company_id in enumerate(company_id_list):\n",
    "    if (c + 1) % 20 == 0:\n",
    "        print(f'Sending description {c + 1} / {len(company_id_list)} to the model')\n",
    "    df_id = df.loc[df['id'] == company_id]\n",
    "\n",
    "    # Mental health predictions\n",
    "    df_id = df_id.assign(**mh_output)\n",
    "    \n",
    "    # Inpatient predictions\n",
    "    df_id = df_id.assign(**ip_output)\n",
    "    \n",
    "    # Outpatient predictions\n",
    "    df_id = df_id.assign(**op_output)\n",
    "\n",
    "    # Add the new data frame to the list\n",
    "    result_df_list.append(df_id)\n",
    "\n",
    "results_df = pd.concat(results_df_list, axis=0, ignore_index=True)\n",
    "# Save the results\n",
    "results_file_name = f'{variable}_{str(prompt_version).zfill(2)}_results.parquet'\n",
    "results_file = os.path.join(data_dir, results_file_name)\n",
    "results_df.to_parquet(results_file)\n",
    "print(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5fb0b-d618-4666-98ee-742f422ef75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a52665-cf21-48f7-8ba2-f82c084cc688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8072d2e-2830-4033-ac94-6f08361d6547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
