{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c034dd-6222-4e73-bd30-6693f4fa62b9",
   "metadata": {},
   "source": [
    "### Script to run all prompts on the data set ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855ae84-3c04-4677-a51d-63a91a96f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Import this module with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import llmt\n",
    "from llmt.llmtools import Prompt\n",
    "from llmt.llmtools import MentalHealth, OutpatientServices, InpatientServices\n",
    "from llmt.llmtools import process_prompt\n",
    "from llmt.openai import OpenAI, create_messages\n",
    "from llmt.performance import Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b1d27-85e6-465b-9d58-c7d5e79d93e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "# Directories and files\n",
    "data_dir = os.path.join(os.environ.get('HOME'), 'home_data', 'hcp')\n",
    "test_file_name = 'hcp-alldata-250413.parquet'\n",
    "test_file = os.path.join(data_dir, test_file_name)\n",
    "df_all = pd.read_parquet(test_file)\n",
    "# Filter the labeled data\n",
    "df_train = df_all.loc[df_all['dset'] == 'train'].\\\n",
    "                reset_index(drop=True).\\\n",
    "                astype({'mental_health': int,\n",
    "                        'inpatient': int,\n",
    "                        'outpatient': int})\n",
    "display(df_train.head())\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac16dc8-640f-4a8e-9240-30328fd4a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some additional samples \n",
    "test_samples = 10\n",
    "random_state = 111\n",
    "df_test = df_all.loc[df_all['mental_health'].isnull()].\\\n",
    "                sample(n=test_samples, replace=False, random_state=random_state).\\\n",
    "                reset_index(drop=True)\n",
    "# Combine the training and test samples\n",
    "df = pd.concat([df_train, df_test], axis=0, ignore_index=True).\\\n",
    "                sample(frac=1, random_state=random_state).\\\n",
    "                reset_index(drop=True)\n",
    "for dset in ['train', 'test']:\n",
    "    print(f'{dset}: {len(df.loc[df['dset']==dset, 'id'].unique())}')\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6d0d9-350e-4338-9016-cac4d42d76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mh(name, description, version, model='gpt-4o', client=None, temperature=0): \n",
    "    variable = 'mental_health'\n",
    "    pred_col = 'pred_mh'\n",
    "    prompt_name = f'{variable}_system_{str(version).zfill(2)}'\n",
    "    system_prompt = Prompt().load(prompt_name=prompt_name)\n",
    "    user_prompt = process_prompt(f\"\"\"\n",
    "                    The organization {name} is described as: {description} \n",
    "                    Does this organization provide {variable} healthcare services?\n",
    "                    \"\"\")\n",
    "    messages = create_messages(system_prompt=system_prompt, user_prompt=user_prompt)\n",
    "    output = OpenAI().send_messages(messages=messages,\n",
    "                                    model=model,\n",
    "                                    temperature=temperature,\n",
    "                                    response_format=MentalHealth,\n",
    "                                    client=client)\n",
    "    # Replace the boolean fields with binary outcome prediction\n",
    "    output.update({pred_col: 1 if output.get(pred_col) == True else 0})\n",
    "    # Select the fields that we want \n",
    "    output = {pred_col: output.get(pred_col)}\n",
    "    return output\n",
    "\n",
    "def predict_ip(name, description, version, model='gpt-4o', client=None, temperature=0): \n",
    "    variable = 'inpatient'\n",
    "    pred_col = 'pred_ip'\n",
    "    prompt_name = f'{variable}_system_{str(version).zfill(2)}'\n",
    "    system_prompt = Prompt().load(prompt_name=prompt_name)\n",
    "    user_prompt = process_prompt(f\"\"\"\n",
    "                    The organization {name} is described as: {description} \n",
    "                    Does this organization provide {variable} healthcare services?\n",
    "                    \"\"\")\n",
    "    messages = create_messages(system_prompt=system_prompt, user_prompt=user_prompt)\n",
    "    output = OpenAI().send_messages(messages=messages,\n",
    "                                    model=model,\n",
    "                                    temperature=temperature,\n",
    "                                    response_format=InpatientServices,\n",
    "                                    client=client)\n",
    "    # Replace the boolean fields with binary outcome prediction\n",
    "    output.update({pred_col: 1 if output.get(pred_col) == True else 0})\n",
    "    # Select the fields that we want \n",
    "    output = {pred_col: output.get(pred_col)}\n",
    "    return output\n",
    "\n",
    "def predict_op(name, description, version, model='gpt-4o', client=None, temperature=0): \n",
    "    variable = 'outpatient'\n",
    "    pred_col = 'pred_op'\n",
    "    prompt_name = f'{variable}_system_{str(version).zfill(2)}'\n",
    "    system_prompt = Prompt().load(prompt_name=prompt_name)\n",
    "    user_prompt = process_prompt(f\"\"\"\n",
    "                    The organization {name} is described as: {description} \n",
    "                    Does this organization provide {variable} healthcare services?\n",
    "                    \"\"\")\n",
    "    messages = create_messages(system_prompt=system_prompt, user_prompt=user_prompt)\n",
    "    output = OpenAI().send_messages(messages=messages,\n",
    "                                    model=model,\n",
    "                                    temperature=temperature,\n",
    "                                    response_format=OutpatientServices,\n",
    "                                    client=client)\n",
    "    # Replace the boolean fields with binary outcome prediction\n",
    "    key_list = [pred_col, 'verified_op']\n",
    "    output.update({key: 1 if output.get(key) == True else 0 for key in key_list})\n",
    "    # Select the fields that we want \n",
    "    output = {pred_col: output.get(pred_col), 'verified_op': output.get('verified_op')}\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1a1e85-90a6-45fa-a699-28a0c4213bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this function\n",
    "company_id_list = sorted(list(df['id'].unique()))\n",
    "company_id = company_id_list[10]\n",
    "df_id = df.loc[df['id'] == company_id]\n",
    "name = df_id['name'].values[0]\n",
    "description = df_id['description'].values[0]\n",
    "client = OpenAI().create_client()\n",
    "\n",
    "model_params = {'model': 'gpt-4o', \n",
    "                'client': client, \n",
    "                'temperature': 0}\n",
    "\n",
    "response_mh = predict_mh(name=name, description=description, version=2, **model_params)\n",
    "print(response_mh)\n",
    "response_ip = predict_ip(name=name, description=description, version=1, **model_params)\n",
    "print(response_ip)\n",
    "response_op = predict_op(name=name, description=description, version=1, **model_params)\n",
    "print(response_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34c8e8-f67f-4a14-ae00-58788f585831",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI().create_client()\n",
    "model_params = {'model': 'gpt-4o', \n",
    "                'client': client, \n",
    "                'temperature': 0}\n",
    "\n",
    "runs = 10\n",
    "\n",
    "# Run the prompt on all data\n",
    "company_id_list = sorted(list(df['id'].unique()))\n",
    "results_df_list = []\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for run in range(runs):\n",
    "    execution_time = time.perf_counter() - start_time\n",
    "    execution_time_min = np.round(execution_time/60, decimals=1)\n",
    "    print(f'Execution time: {execution_time_min} minutes.')\n",
    "    print(f'STARTING RUN {run + 1} / {runs}')\n",
    "    for c, company_id in enumerate(company_id_list):\n",
    "        if (c + 1) % 20 == 0:\n",
    "            print(f'Sending description {c + 1} / {len(company_id_list)} to the model')\n",
    "    \n",
    "        df_id = df.loc[df['id'] == company_id]\n",
    "        name = df_id['name'].values[0]\n",
    "        description = df_id['description'].values[0]\n",
    "        \n",
    "        # Mental health predictions\n",
    "        response_mh = predict_mh(name=name, description=description, version=2, **model_params)\n",
    "        df_id = df_id.assign(**response_mh)\n",
    "        \n",
    "        # Inpatient predictions\n",
    "        response_ip = predict_ip(name=name, description=description, version=1, **model_params)\n",
    "        df_id = df_id.assign(**response_ip)\n",
    "        \n",
    "        # Outpatient predictions\n",
    "        response_op = predict_op(name=name, description=description, version=1, **model_params)\n",
    "        df_id = df_id.assign(**response_op)\n",
    "\n",
    "        # Add the new data frame to the list\n",
    "        df_id = df_id.assign(run=run, \n",
    "                             temp=model_params.get('temperature'))\n",
    "        results_df_list.append(df_id)\n",
    "\n",
    "results_df = pd.concat(results_df_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Save the results\n",
    "results_file_name = f'250420_results_10_runs.parquet'\n",
    "results_file = os.path.join(data_dir, results_file_name)\n",
    "results_df.to_parquet(results_file)\n",
    "print(results_file)\n",
    "end_time = time.perf_counter()\n",
    "execution_time = end_time - start_time\n",
    "execution_time_min = np.round(execution_time/60, decimals=1)\n",
    "print(f'Execution time: {execution_time_min} minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89aca69-9d9d-44ee-8d0f-c4e9fe47a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and check the results\n",
    "# results_file_name = 'inpatient_01_results.parquet'\n",
    "results_file_name = f'250420_results_10_runs.parquet'\n",
    "results_file = os.path.join(data_dir, results_file_name)\n",
    "df = pd.read_parquet(results_file)\n",
    "\n",
    "results_train = df.loc[df['dset'] == 'train']\n",
    "\n",
    "# Mapping true variable and predictions\n",
    "variable_dict = {'mental_health': 'pred_mh',\n",
    "                 'inpatient': 'pred_ip',\n",
    "                 'outpatient': 'pred_op'}\n",
    "\n",
    "for true_col in variable_dict.keys():\n",
    "    print(f'PERFORMANCE: {true_col.upper()}')\n",
    "    display(Performance(data=df.copy()).\\\n",
    "            binary_performance(true_col=true_col, pred_col=variable_dict.get(true_col)))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
