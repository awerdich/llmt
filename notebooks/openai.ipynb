{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb778cb-e3f5-4ec1-b0d2-d8764cb90663",
   "metadata": {},
   "source": [
    "### Getting started with the OpenAI library ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b68ce7a-d58b-49f7-b517-17fdae85ba35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent\n",
    "\n",
    "# OpenAI libraries\n",
    "from openai import AzureOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# Appearance of the Notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "np.set_printoptions(linewidth=110)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# Import this module with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import llmt\n",
    "# print(f'Package version: {llmt.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e2572f-af6b-4831-af16-ed4d1a348f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /home/andreas/data/hcp\n"
     ]
    }
   ],
   "source": [
    "# Data directory and files\n",
    "data_dir = os.path.join(os.environ.get('HOME'), 'data', 'hcp')\n",
    "print(f'Data directory: {data_dir}')\n",
    "\n",
    "# Data set\n",
    "# xls_name = 'inpatient-companies-classification-Additional negs-04.01.2025.xlsx'\n",
    "# xls_file = os.path.join(data_dir, xls_name)\n",
    "# xdf = pd.read_excel(xls_file)\n",
    "# display(xdf.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187890b5-2392-45e8-a4d8-c13bed89cd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using API key:  hcp\n"
     ]
    }
   ],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "api_endpoint = os.environ.get('API_ENDPOINT')\n",
    "api_key = os.environ.get('API_KEY')\n",
    "api_project = os.environ.get('API_PROJECT')\n",
    "print(f'Using API key:  {api_project}')\n",
    "# api_version = '2024-05-01-preview'\n",
    "api_version = '2025-02-01-preview'\n",
    "# Model name needs to be in the deployment for the endpoint\n",
    "model_name = 'gpt-4o'\n",
    "# Now, we can create the API client\n",
    "client = AzureOpenAI(api_key=api_key, \n",
    "                     azure_endpoint=api_endpoint,\n",
    "                     api_version=api_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee259bd-81ba-454b-9a6c-088bf19ea523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message_list(system_message, user_message):\n",
    "    # Encode the image\n",
    "    system_dict = {'role': 'system',\n",
    "                   'content': dedent(system_message)}\n",
    "    user_dict = {'role': 'user',\n",
    "                 'content': [{'type': 'text', 'text': dedent(user_message)}]}\n",
    "    message_list = [system_dict, user_dict]\n",
    "    return message_list\n",
    "\n",
    "# Function to create the output message\n",
    "def send_messages(model, temperature, messages):\n",
    "    try:\n",
    "        output = client.chat.completions.create(model=model, \n",
    "                                                messages=messages, \n",
    "                                                temperature=temperature)\n",
    "    except Exception as e:\n",
    "        print(f'ERROR: {e}')\n",
    "        response = None\n",
    "    else:\n",
    "        response = output.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e547947f-fa31-4295-8ded-d38914d8c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Connection error.\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"You are a powerful AI system.\"\"\"\n",
    "user_message = \"\"\"Define large language model.\"\"\"\n",
    "messages = create_message_list(system_message=system_message, user_message=user_message)\n",
    "\n",
    "# Send the messages\n",
    "model = 'gpt-4o'\n",
    "temperature = 0.5\n",
    "response = send_messages(model=model, temperature=temperature, messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7781213-9952-4874-99e0-e4c21ad343d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A **large language model (LLM)** is a type of artificial intelligence (AI) system designed to process and generate human-like text based on patterns it has learned from vast amounts of text data. These models are built using deep learning architectures, typically **transformers**, and are trained on extensive datasets that include books, articles, websites, and other written content.\n",
      "\n",
      "Key characteristics of large language models:\n",
      "\n",
      "1. **Scale**:  \n",
      "   LLMs are distinguished by their size, often measured in terms of the number of parameters (trainable weights in the model). These models can range from millions to hundreds of billions of parameters, enabling them to capture and generate complex language patterns.\n",
      "\n",
      "2. **Versatility**:  \n",
      "   LLMs can perform a wide range of language-related tasks, including:  \n",
      "   - Text generation  \n",
      "   - Language translation  \n",
      "   - Summarization  \n",
      "   - Question answering  \n",
      "   - Sentiment analysis  \n",
      "   - Code generation  \n",
      "   - And more.\n",
      "\n",
      "3. **Pretraining and Fine-tuning**:  \n",
      "   LLMs are typically pretrained on large, general-purpose datasets in an unsupervised manner (e.g., predicting the next word in a sentence). After pretraining, they can be fine-tuned on specific tasks or domains to improve performance in specialized applications.\n",
      "\n",
      "4. **Contextual Understanding**:  \n",
      "   LLMs use context to generate coherent and contextually relevant responses. They can handle long-range dependencies in text, making them effective at understanding and producing nuanced, human-like language.\n",
      "\n",
      "Examples of large language models include **OpenAI's GPT series (e.g., GPT-4)**, **Google's PaLM**, **Meta's LLaMA**, and **Anthropic's Claude**.\n",
      "\n",
      "While LLMs are powerful and widely applicable, they also have limitations, such as susceptibility to generating incorrect or biased information, lack of true understanding, and high computational resource requirements.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
